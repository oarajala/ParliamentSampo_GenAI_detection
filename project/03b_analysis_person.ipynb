{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3d86c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages, declare constants, get the parent directory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "#from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "#from .utils import helpers\n",
    "import simplemma\n",
    "import pyvoikko\n",
    "import decimal\n",
    "import numpy as np\n",
    "\n",
    "FINNISH_ALPHABET = 'abcdefghijklmnopqrstuvwxyzåäö'\n",
    "\n",
    "def get_parent_directory() -> str:\n",
    "    \"\"\"Get the parent directory for handling csv files.\n",
    "\n",
    "    Returns:\n",
    "        string: the path to the directory where directories for csv files are located\n",
    "    \"\"\"\n",
    "    #create relative path for parent\n",
    "    relative_parent = os.path.join(os.getcwd(), '..')\n",
    "\n",
    "    #use abspath for absolute parent path\n",
    "    return str(os.path.abspath(relative_parent)).replace('\\\\', '/')\n",
    "\n",
    "directory = get_parent_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea30949",
   "metadata": {},
   "source": [
    "DECLARE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dcda5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string: str) -> str:\n",
    "    try:\n",
    "        # remove blanks in start and end\n",
    "        string = string.strip()\n",
    "        string = string.lower()\n",
    "        # the string must contain characters\n",
    "        if any(c in string for c in FINNISH_ALPHABET)==False:\n",
    "            string = ''\n",
    "        # remove tabulations, line breaks etc., also special characters\n",
    "        remove_these = r'[\\+\\*!\"”?.,…()§\\'[\\] \\t\\n\\r\\f\\v]'\n",
    "        string = re.sub(remove_these, '', string)\n",
    "        # remove weird parentheses and backwards linebreaks from starts of strings\n",
    "        string = re.sub(r'^\\)\\\\[a-z]', '', string)\n",
    "        # remove weird '\\[alphabet]' strings at start of strings\n",
    "        string = re.sub(r'^\\\\[a-z]', '', string)\n",
    "        # remove numbers\n",
    "        string = re.sub(r'[0-9]', '', string)\n",
    "        # remove dashes '-' at the start and end of string\n",
    "        string = re.sub(r'^-|-$', '', string)\n",
    "        # remove individual forward and backward slashes '/', '\\'\n",
    "        string = re.sub(r'[\\/\\\\]', '', string)\n",
    "        # remove double dashes '--'\n",
    "        string = string.replace('--', '-')\n",
    "        # remove the equal sign '='\n",
    "        string = string.replace('=', '')\n",
    "        # at the end of the cleaning, remove all characters from the string which are not in the alphabet except for dash (compound words)\n",
    "        remove_these = ''.join([str(c) for c in string if c != '-' and c not in [i for i in FINNISH_ALPHABET]])\n",
    "        string = re.sub(remove_these, '', string)\n",
    "        # remove blanks in start and end again\n",
    "        string = string.strip()\n",
    "        # remove empty if string length < 2\n",
    "        string = '' if len(string) < 2 else string\n",
    "        return string\n",
    "    except:\n",
    "        print(f'Unexpected error at helpers.clean_string(), string: {string}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3354488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_freqs_in_string(string: str):\n",
    "    \"\"\"Counts the words in the input string.\n",
    "    Returns a dictionary where the word is the key and the frequency is the value.\n",
    "    \"\"\"\n",
    "    if ((string is None) or (string == 'nan')):\n",
    "        return None\n",
    "    else:\n",
    "        words_list = re.split(' ', string)\n",
    "        wordfreq_dict = {}\n",
    "        for word in words_list:\n",
    "            if word not in wordfreq_dict.keys():\n",
    "                wordfreq_dict[word] = 1\n",
    "            else:\n",
    "                wordfreq_dict[word] += 1\n",
    "\n",
    "        return wordfreq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "662ec8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lemmatised csvs for years 2015-2025\n",
    "# the goal is to check if word frequencies per SPEAKER change over years\n",
    "\n",
    "df = pd.read_csv(f'{directory}/csv_lemmatized/speeches_2015.csv', sep=';', encoding='utf-8', header=0, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6654f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean 'speaker_id' column\n",
    "\n",
    "df['speaker_id'] = df.apply(lambda x: str(x['speaker_id']).strip() if ((x['speaker_id'] is not None) & (x['speaker_id'] is not np.nan)) else x['speaker_id'], axis=1)\n",
    "df['speaker_id'] = df.apply(lambda x: '' if x['speaker_id']=='nan' else x['speaker_id'], axis=1)\n",
    "# df['speaker_id'].loc[(df['speaker_id'].notna()==True)&(df['speaker_id'].str.len()>0)].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f99bbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data in loops: \n",
    "## > loop the csvs for years 2015-2025\n",
    "## > extract each word per speaker per df (=year), this is done in a for loop\n",
    "## > combine them all into dataframe df_speaker_words_year\n",
    "# declare the years\n",
    "year, max_year = 2015, 2025\n",
    "# start looping the csvs\n",
    "while year <= max_year:\n",
    "    # name for saving the file\n",
    "    save_file_name = f'speaker_words_{year}.csv'\n",
    "    if save_file_name in os.listdir(f'{directory}/csv_analysis/'):\n",
    "        pass\n",
    "    else:\n",
    "        # get the csv to match the year from directory: directory/csv_lemmatized/\n",
    "        year_csv = pd.read_csv(f'{directory}/csv_lemmatized/speeches_{year}.csv', sep=';', header=0)\n",
    "        # format a dataframe to store the results\n",
    "        # > columns: speaker_id, year, word, word_n (how many times the word appears)\n",
    "        df_speaker_words_year = pd.DataFrame(columns=['speaker_id', 'year', 'word', 'word_n']).astype({'speaker_id': str, 'year': int, 'word': str, 'word_n': int})    \n",
    "        # extract each word per speaker per df (=year)\n",
    "        for speaker in year_csv['speaker_id'].loc[(year_csv['speaker_id'].notna()==True)&(year_csv['speaker_id'].str.len()>0)].unique():\n",
    "            # extract only rows for the speaker in iteration, and only if a lemmatized speech exists, and only if the lemmatized speech is longer than 0 chars\n",
    "            df_filtered = year_csv.loc[(year_csv['speaker_id']==speaker)&(year_csv['content_lemmatized'].notna()==True)&(year_csv['content_lemmatized'].str.len()>0)]\n",
    "            # extract each lemmatized speech; compile them into a single string\n",
    "            speaker_all_speeches = ' '.join(df_filtered['content_lemmatized'])\n",
    "            # string cleaning: clean special characters from the string\n",
    "            speaker_all_speeches = ' '.join([clean_string(word) for word in speaker_all_speeches.split(' ')])\n",
    "            # get the count of each word in the string, return a dict\n",
    "            speaker_words_dict = count_word_freqs_in_string(speaker_all_speeches)\n",
    "            # delete empty '' keys (words) from the dict, if such have made it there. these are failed lemmatizations\n",
    "            try:\n",
    "                del speaker_words_dict['']\n",
    "            except KeyError:\n",
    "                pass\n",
    "            # add the speaker's subset (speaker_id, year, word, word_n) in the combination dataframe\n",
    "            # > from the speaker_words_dict, and year, and speaker\n",
    "            # > create another \"temporary\" dataframe for this, concatenate this to the df_speaker_words_year df\n",
    "            concat_df = pd.DataFrame.from_dict(data=speaker_words_dict, orient='index', columns=['word_n'])\n",
    "            concat_df['speaker_id'], concat_df['year'], concat_df['word'] = year, speaker, concat_df.index\n",
    "            concat_df.reset_index(drop=True, inplace=True)\n",
    "            concat_df = concat_df[['speaker_id','year','word','word_n']]  \n",
    "            df_speaker_words_year = pd.concat([df_speaker_words_year, concat_df], axis=0, ignore_index=True)\n",
    "            #for k, v in speaker_words_dict.items():\n",
    "            #    df_speaker_words_year = pd.concat([df_speaker_words_year, pd.DataFrame.from_dict(data={'speaker_id': [speaker], 'year': [year], 'word': [k], 'word_n': [v]}, orient='columns')], axis=0, ignore_index=True)\n",
    "        # store the data in a csv (savepoint!)\n",
    "        # > directory and file name template: directory/csv_analysis/speaker_words_YYYY.csv\n",
    "        df_speaker_words_year.to_csv(f'{directory}/csv_analysis/{save_file_name}', sep=';', header=True, index=False, encoding='utf-8')\n",
    "        # time for the next year\n",
    "    year = year+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "81d0b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word_n\n",
      "arvoisa        43\n",
      "rouva          15\n",
      "puhemies       48\n",
      "haluta         12\n",
      "aloittaa        2\n",
      "...           ...\n",
      "korjaus         1\n",
      "lindtman        1\n",
      "vähennys        1\n",
      "taksiauto       1\n",
      "hankinta        1\n",
      "\n",
      "[1340 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#df_speaker_words_year['speaker_id'].unique()\n",
    "#pd.DataFrame.from_dict(data={'speaker_id': [speaker], 'year': [year], 'word': [speaker_words_dict.keys()], 'word_n': [speaker_words_dict.values()]})\n",
    "a = pd.DataFrame.from_dict(data=speaker_words_dict, orient='index', columns=['word_n'])\n",
    "#a['word'] = a.index\n",
    "#a['speaker_id'], a['year'], a['word'] = year, speaker, a.index\n",
    "#a.reset_index(drop=True, inplace=True)\n",
    "#a = a[['speaker_id','year','word','word_n']]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1ef2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
